{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import json\n",
    "from pyzipcode import ZipCodeDatabase\n",
    "import string\n",
    "import colour\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "trash=[1,2]\n",
    "[t1,t2]=trash\n",
    "print t1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only use those areas where I have pricing information.\n",
    "\n",
    "#normalize percentage increase by area.\n",
    "def samNormalize(I_array):\n",
    "    normval=np.nanmean(I_array)\n",
    "    return np.divide(I_array,normval)\n",
    "\n",
    "def samLatLon(I_array, weights=1):\n",
    "    #determine mean\n",
    "    citycenter= np.nanmean(I_array,axis=0)\n",
    "    \n",
    "    #determine distance from mean\n",
    "    O_array=I_array\n",
    "    O_array[:,0]=np.subtract(I_array[:,0],citycenter[0])\n",
    "    O_array[:,1]=np.subtract(I_array[:,1],citycenter[1])\n",
    "    dists=np.sqrt(np.add(np.square(O_array[:,0]),np.square(O_array[:,1])))\n",
    "    return samNormalize(dists)\n",
    "\n",
    "def samRank(I_array):\n",
    "    #from High to Low\n",
    "    order = I_array.argsort()[::-1]\n",
    "    return order.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def samlinearFit(df, stopdate, predictdate):\n",
    "    #create linear fit for each row\n",
    "    full_price_df=df.iloc[:,6:71]\n",
    "    \n",
    "    normdate=np.datetime64('2014-01')\n",
    "    \n",
    "    #determine dates\n",
    "    dates=[np.datetime64(date) for date in list(full_price_df.columns.values)]\n",
    "    id_pr=np.argmax(dates>predictdate)\n",
    "    id_in=np.argmax(dates>stopdate)\n",
    "    id_no=np.argmax(dates>normdate)\n",
    "    \n",
    "    #build dataframe, normalize by value at input time\n",
    "    full_price_df = full_price_df.div(full_price_df.iloc[:,id_no],axis='index')\n",
    "    myrange,=np.where(dates<stopdate)\n",
    "    newdf=full_price_df.iloc[:,myrange]\n",
    "    \n",
    "    #establish variables\n",
    "    flag=[]\n",
    "    \n",
    "    slope=np.empty(df.shape)\n",
    "    inter=np.empty(df.shape)\n",
    "    NANs=np.empty([1,2])\n",
    "    NANs[:]=np.NAN\n",
    "    print NANs\n",
    "    for i_, row in newdf.iterrows():\n",
    "        if i_%500==0:\n",
    "            print i_\n",
    "        \n",
    "        for j_, cutoff in enumerate(myrange):\n",
    "            i_df=pd.DataFrame({'price':row.values[:j_],'date':range(myrange.size)[:j_]})\n",
    "            \n",
    "            try:\n",
    "                result = sm.ols(formula=\"price ~ date\", data=i_df).fit()\n",
    "                [inter[i_,j_], slope[i_, j_]]=result.params.values\n",
    "                    \n",
    "            except:\n",
    "                [inter[i_,j_], slope[i_, j_]]=NANs[0]\n",
    "                flag.append(i_)\n",
    "        \n",
    "    \n",
    "    return inter, slope, newdf, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10728\n"
     ]
    }
   ],
   "source": [
    "print df.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get real estate data\n",
    "# http://www.zillow.com/research/data/\n",
    "filename='../../Data/Zillow/Zip/Zip_MedianRentalPricePerSqft_AllHomes.csv'\n",
    "filename='../../Data/Zillow/Zip/Zip_MedianListingPricePerSqft_AllHomes.csv'\n",
    "with open(filename,'r') as zf:\n",
    "    df=pd.read_csv(zf,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan]]\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "#separate into pre/post 2014\n",
    "#Use info from pre-2014 to train model based on 2015 real estate estimates.\n",
    "featurenames=['Intercept','Slope']\n",
    "inter14, slope14, new_df14, flag14=samlinearFit(df,np.datetime64('2014-01'),np.datetime64('2016-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan]]\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "#separate into pre/post 2014\n",
    "#Use info from pre-2014 to train model based on 2015 real estate estimates.\n",
    "featurenames=['Intercept','Slope']\n",
    "inter16, slope16, new_df16, flag16=samlinearFit(df,np.datetime64('2016-06'),np.datetime64('2016-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get real estate data\n",
    "# http://www.zillow.com/research/data/\n",
    "filename='../../Data/Zillow/Zip/Zip_MedianRentalPricePerSqft_AllHomes.csv'\n",
    "with open(filename,'r') as zf:\n",
    "    df=pd.read_csv(zf,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan]]\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "#separate into pre/post 2014\n",
    "#Use info from pre-2014 to train model based on 2015 real estate estimates.\n",
    "featurenames=['Intercept','Slope']\n",
    "inter_rent14, slope_rent14, new_df_rent14, flag14=samlinearFit(df,np.datetime64('2014-01'),np.datetime64('2016-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan]]\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "#separate into pre/post 2014\n",
    "#Use info from pre-2014 to train model based on 2015 real estate estimates.\n",
    "featurenames=['Intercept','Slope']\n",
    "inter_rent16, slope_rent16, new_df_rent16, flag16=samlinearFit(df,np.datetime64('2016-06'),np.datetime64('2016-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start creating features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'percChange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-59ec15715792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mnormPC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mpercChange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpercChange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'percChange' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "zips=df['RegionName'].values\n",
    "ranks=np.ones((zips.size))*np.NAN\n",
    "zcdb = ZipCodeDatabase()\n",
    "\n",
    "lat=[]\n",
    "lon=[]\n",
    "state=[]\n",
    "for z in zips:\n",
    "    try:\n",
    "        zc=zcdb[z]\n",
    "    except:\n",
    "        lat.append(np.NAN)\n",
    "        lon.append(np.NAN)\n",
    "        state.append(np.NAN)\n",
    "        continue\n",
    "    state.append(state_nums[str(zc.state)])\n",
    "    lat.append(zc.latitude)\n",
    "    lon.append(zc.longitude)\n",
    "\n",
    "state=np.asarray(state)\n",
    "lat=np.asarray(lat)\n",
    "lon=np.asarray(lon)\n",
    "normPC=ranks\n",
    "\n",
    "percChange=percChange.values\n",
    "for i in range(50):\n",
    "    index=np.where(state==i)\n",
    "    \n",
    "    normPC[index]=samNormalize(percChange[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "slopeInt, flag, perc, trash= samlinearFit(df,np.datetime64('2016-06'),np.datetime64('2016-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12.  42.  12. ...,  17.  31.  16.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'normPC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-262dcf0cfe03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# r_io=np.column_stack((slopeInt,dists,percChange,rank2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mr_io\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslopeInt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormPC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mr_io\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr_io\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normPC' is not defined"
     ]
    }
   ],
   "source": [
    "plt.close()\n",
    "\n",
    "\n",
    "print state\n",
    "# r_io=np.column_stack((slopeInt,dists,percChange,rank2))\n",
    "r_io=np.column_stack((slopeInt,state,lon,lat,normPC,ranks))\n",
    "r_io=r_io[~np.isnan(r_io).any(axis=1)]\n",
    "\n",
    "fig, axes=plt.subplots(ncols=1, nrows=2, figsize=[6,5])\n",
    "axes[0].scatter(normPC, slopeInt[:,0])\n",
    "# axes[0].set_ylim([-.02, .02])\n",
    "axes[1].hist(r_io[:,-2],100)\n",
    "\n",
    "plt.show()\n",
    "stop\n",
    "\n",
    "ip=r_io[:,0:5]\n",
    "print ip.shape\n",
    "op=r_io[:,-1]\n",
    "skf = StratifiedKFold(op, n_folds=3)\n",
    "for fold, (tr, te) in enumerate(skf):\n",
    "    rnf = RandomForestClassifier(n_estimators=100, max_depth=None,\n",
    "        min_samples_split=50, max_features=2, random_state=1, max_leaf_nodes=30)\n",
    "    rnf2=rnf\n",
    "    \n",
    "    rnf.fit(ip[tr,:],op[tr])\n",
    "#     print rnf.predict(r_io[0:100,0:3])\n",
    "    newte=te[op[te]==1]\n",
    "#     te=newte\n",
    "    print ('Fold:%i, G0:%.2f, G1:%.2f, G2:%.2f, G3:%.2f, G4:%.2f, RNF: %.3f' %\n",
    "        (fold, accuracy_score(op[te], rnf.predict(ip[te,:])*0.+0.), \n",
    "         accuracy_score(op[te], rnf.predict(ip[te,:])*0.+1.), \n",
    "         accuracy_score(op[te], rnf.predict(ip[te,:])*0.+2.), \n",
    "         accuracy_score(op[te], rnf.predict(ip[te,:])*0.+3.), \n",
    "         accuracy_score(op[te], rnf.predict(ip[te,:])*0.+4.), \n",
    "         accuracy_score(op[te], rnf.predict(ip[te,:]))))\n",
    "\n",
    "\n",
    "plot_learning_curve(rnf2,'Random Forest',ip,op,(0,1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "state_abrevs=dict((v, k) for k, v in states.iteritems())\n",
    "state_nums=dict((k[0],id_) for id_, k  in enumerate(states.iteritems()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
